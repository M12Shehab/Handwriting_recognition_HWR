{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9d203c6-0fe1-4993-aed0-fa23769c10f3",
   "metadata": {},
   "source": [
    "# Handwriting recognition (HWR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c65607-9c22-4d01-b133-dcb2cba807f9",
   "metadata": {},
   "source": [
    "### Author: Mohammed Shehab\n",
    "\n",
    "This script provides a comprehensive guide to:\n",
    "1. Loading and preprocessing the dataset\n",
    "2. Constructing a Convolutional Neural Network (CNN) model architecture\n",
    "3. Performing hyperparameter tuning to optimize the CNN model\n",
    "4. Exporting the best-performing model for deployment\n",
    "\n",
    "**Deployment will be facilitated using Docker containerization to ensure a scalable and reproducible environment.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05b49239-2787-417e-8a42-dc80d370ea8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlflow\n",
      "  Downloading mlflow-2.16.2-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting mlflow-skinny==2.16.2 (from mlflow)\n",
      "  Downloading mlflow_skinny-2.16.2-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting Flask<4 (from mlflow)\n",
      "  Downloading flask-3.0.3-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting alembic!=1.10.0,<2 (from mlflow)\n",
      "  Downloading alembic-1.13.3-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting docker<8,>=4.0.0 (from mlflow)\n",
      "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting graphene<4 (from mlflow)\n",
      "  Downloading graphene-3.3-py2.py3-none-any.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: markdown<4,>=3.3 in c:\\users\\shehab\\anaconda3\\envs\\py310\\lib\\site-packages (from mlflow) (3.5.2)\n",
      "Requirement already satisfied: matplotlib<4 in c:\\users\\shehab\\anaconda3\\envs\\py310\\lib\\site-packages (from mlflow) (3.8.0)\n",
      "Requirement already satisfied: numpy<3 in c:\\users\\shehab\\anaconda3\\envs\\py310\\lib\\site-packages (from mlflow) (1.26.3)\n",
      "Requirement already satisfied: pandas<3 in c:\\users\\shehab\\anaconda3\\envs\\py310\\lib\\site-packages (from mlflow) (2.2.2)\n",
      "Collecting pyarrow<18,>=4.0.0 (from mlflow)\n",
      "  Downloading pyarrow-17.0.0-cp310-cp310-win_amd64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: scikit-learn<2 in c:\\users\\shehab\\anaconda3\\envs\\py310\\lib\\site-packages (from mlflow) (1.3.0)\n",
      "Requirement already satisfied: scipy<2 in c:\\users\\shehab\\anaconda3\\envs\\py310\\lib\\site-packages (from mlflow) (1.11.4)\n",
      "Collecting sqlalchemy<3,>=1.4.0 (from mlflow)\n",
      "  Downloading SQLAlchemy-2.0.35-cp310-cp310-win_amd64.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: Jinja2<4,>=3.0 in c:\\users\\shehab\\anaconda3\\envs\\py310\\lib\\site-packages (from mlflow) (3.1.3)\n",
      "Collecting waitress<4 (from mlflow)\n",
      "  Downloading waitress-3.0.0-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: cachetools<6,>=5.0.0 in c:\\users\\shehab\\anaconda3\\envs\\py310\\lib\\site-packages (from mlflow-skinny==2.16.2->mlflow) (5.3.2)\n",
      "Collecting click<9,>=7.0 (from mlflow-skinny==2.16.2->mlflow)\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting cloudpickle<4 (from mlflow-skinny==2.16.2->mlflow)\n",
      "  Downloading cloudpickle-3.1.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==2.16.2->mlflow)\n",
      "  Downloading databricks_sdk-0.34.0-py3-none-any.whl.metadata (37 kB)\n",
      "Collecting gitpython<4,>=3.1.9 (from mlflow-skinny==2.16.2->mlflow)\n",
      "  Using cached GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting importlib-metadata!=4.7.0,<9,>=3.7.0 (from mlflow-skinny==2.16.2->mlflow)\n",
      "  Downloading importlib_metadata-8.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting opentelemetry-api<3,>=1.9.0 (from mlflow-skinny==2.16.2->mlflow)\n",
      "  Downloading opentelemetry_api-1.27.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-sdk<3,>=1.9.0 (from mlflow-skinny==2.16.2->mlflow)\n",
      "  Downloading opentelemetry_sdk-1.27.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: packaging<25 in c:\\users\\shehab\\anaconda3\\envs\\py310\\lib\\site-packages (from mlflow-skinny==2.16.2->mlflow) (23.1)\n",
      "Requirement already satisfied: protobuf<6,>=3.12.0 in c:\\users\\shehab\\anaconda3\\envs\\py310\\lib\\site-packages (from mlflow-skinny==2.16.2->mlflow) (3.19.6)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in c:\\users\\shehab\\anaconda3\\envs\\py310\\lib\\site-packages (from mlflow-skinny==2.16.2->mlflow) (6.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in c:\\users\\shehab\\anaconda3\\envs\\py310\\lib\\site-packages (from mlflow-skinny==2.16.2->mlflow) (2.31.0)\n",
      "Collecting sqlparse<1,>=0.4.0 (from mlflow-skinny==2.16.2->mlflow)\n",
      "  Downloading sqlparse-0.5.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting Mako (from alembic!=1.10.0,<2->mlflow)\n",
      "  Downloading Mako-1.3.5-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4 in c:\\users\\shehab\\anaconda3\\envs\\py310\\lib\\site-packages (from alembic!=1.10.0,<2->mlflow) (4.9.0)\n",
      "Requirement already satisfied: pywin32>=304 in c:\\users\\shehab\\anaconda3\\envs\\py310\\lib\\site-packages (from docker<8,>=4.0.0->mlflow) (305.1)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\shehab\\anaconda3\\envs\\py310\\lib\\site-packages (from docker<8,>=4.0.0->mlflow) (2.1.0)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in c:\\users\\shehab\\anaconda3\\envs\\py310\\lib\\site-packages (from Flask<4->mlflow) (3.0.1)\n",
      "Collecting itsdangerous>=2.1.2 (from Flask<4->mlflow)\n",
      "  Downloading itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting blinker>=1.6.2 (from Flask<4->mlflow)\n",
      "  Downloading blinker-1.8.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n",
      "  Downloading graphql_core-3.2.4-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n",
      "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting aniso8601<10,>=8 (from graphene<4->mlflow)\n",
      "  Downloading aniso8601-9.0.1-py2.py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\shehab\\anaconda3\\envs\\py310\\lib\\site-packages (from Jinja2<4,>=3.0->mlflow) (2.1.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\shehab\\anaconda3\\envs\\py310\\lib\\site-packages (from matplotlib<4->mlflow) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\shehab\\anaconda3\\envs\\py310\\lib\\site-packages (from matplotlib<4->mlflow) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\shehab\\anaconda3\\envs\\py310\\lib\\site-packages (from matplotlib<4->mlflow) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\shehab\\anaconda3\\envs\\py310\\lib\\site-packages (from matplotlib<4->mlflow) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\shehab\\anaconda3\\envs\\py310\\lib\\site-packages (from matplotlib<4->mlflow) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\shehab\\anaconda3\\envs\\py310\\lib\\site-packages (from matplotlib<4->mlflow) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\shehab\\anaconda3\\envs\\py310\\lib\\site-packages (from matplotlib<4->mlflow) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\shehab\\anaconda3\\envs\\py310\\lib\\site-packages (from pandas<3->mlflow) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\shehab\\anaconda3\\envs\\py310\\lib\\site-packages (from pandas<3->mlflow) (2024.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\shehab\\anaconda3\\envs\\py310\\lib\\site-packages (from scikit-learn<2->mlflow) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\shehab\\anaconda3\\envs\\py310\\lib\\site-packages (from scikit-learn<2->mlflow) (2.2.0)\n",
      "Collecting greenlet!=0.4.17 (from sqlalchemy<3,>=1.4.0->mlflow)\n",
      "  Downloading greenlet-3.1.1-cp310-cp310-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\shehab\\anaconda3\\envs\\py310\\lib\\site-packages (from click<9,>=7.0->mlflow-skinny==2.16.2->mlflow) (0.4.6)\n",
      "Requirement already satisfied: google-auth~=2.0 in c:\\users\\shehab\\anaconda3\\envs\\py310\\lib\\site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.16.2->mlflow) (2.28.0)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython<4,>=3.1.9->mlflow-skinny==2.16.2->mlflow)\n",
      "  Using cached gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting zipp>=3.20 (from importlib-metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.16.2->mlflow)\n",
      "  Downloading zipp-3.20.2-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.16.2->mlflow)\n",
      "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting importlib-metadata!=4.7.0,<9,>=3.7.0 (from mlflow-skinny==2.16.2->mlflow)\n",
      "  Downloading importlib_metadata-8.4.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.48b0 (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.16.2->mlflow)\n",
      "  Downloading opentelemetry_semantic_conventions-0.48b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\shehab\\anaconda3\\envs\\py310\\lib\\site-packages (from python-dateutil>=2.7->matplotlib<4->mlflow) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\shehab\\anaconda3\\envs\\py310\\lib\\site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.16.2->mlflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shehab\\anaconda3\\envs\\py310\\lib\\site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.16.2->mlflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shehab\\anaconda3\\envs\\py310\\lib\\site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.16.2->mlflow) (2024.7.4)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\shehab\\anaconda3\\envs\\py310\\lib\\site-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.16.2->mlflow) (1.16.0)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.16.2->mlflow)\n",
      "  Using cached smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\shehab\\anaconda3\\envs\\py310\\lib\\site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.16.2->mlflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\shehab\\anaconda3\\envs\\py310\\lib\\site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.16.2->mlflow) (4.9)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\shehab\\anaconda3\\envs\\py310\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.16.2->mlflow) (0.5.1)\n",
      "Downloading mlflow-2.16.2-py3-none-any.whl (26.7 MB)\n",
      "   ---------------------------------------- 0.0/26.7 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.5/26.7 MB 14.9 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 1.4/26.7 MB 18.1 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 3.0/26.7 MB 23.7 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 3.6/26.7 MB 20.9 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 4.6/26.7 MB 21.0 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 6.1/26.7 MB 22.9 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 7.6/26.7 MB 24.2 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 9.5/26.7 MB 26.5 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 10.6/26.7 MB 27.3 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 12.3/26.7 MB 29.7 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 13.7/26.7 MB 31.2 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 15.1/26.7 MB 32.7 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 16.4/26.7 MB 32.7 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 17.9/26.7 MB 32.7 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 19.8/26.7 MB 32.8 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 20.6/26.7 MB 32.7 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 21.8/26.7 MB 31.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 23.4/26.7 MB 29.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 24.6/26.7 MB 29.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.1/26.7 MB 29.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.6/26.7 MB 28.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.7/26.7 MB 27.3 MB/s eta 0:00:00\n",
      "Downloading mlflow_skinny-2.16.2-py3-none-any.whl (5.6 MB)\n",
      "   ---------------------------------------- 0.0/5.6 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.3/5.6 MB 6.8 MB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 0.6/5.6 MB 7.9 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 1.9/5.6 MB 13.2 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 3.6/5.6 MB 18.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 4.9/5.6 MB 20.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.6/5.6 MB 21.0 MB/s eta 0:00:00\n",
      "Downloading alembic-1.13.3-py3-none-any.whl (233 kB)\n",
      "   ---------------------------------------- 0.0/233.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 233.2/233.2 kB 13.9 MB/s eta 0:00:00\n",
      "Downloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
      "   ---------------------------------------- 0.0/147.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 147.8/147.8 kB 8.6 MB/s eta 0:00:00\n",
      "Downloading flask-3.0.3-py3-none-any.whl (101 kB)\n",
      "   ---------------------------------------- 0.0/101.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 101.7/101.7 kB ? eta 0:00:00\n",
      "Downloading graphene-3.3-py2.py3-none-any.whl (128 kB)\n",
      "   ---------------------------------------- 0.0/128.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 128.2/128.2 kB ? eta 0:00:00\n",
      "Downloading pyarrow-17.0.0-cp310-cp310-win_amd64.whl (25.1 MB)\n",
      "   ---------------------------------------- 0.0/25.1 MB ? eta -:--:--\n",
      "   - -------------------------------------- 1.1/25.1 MB 22.9 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 2.8/25.1 MB 29.9 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 3.8/25.1 MB 27.2 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 5.5/25.1 MB 29.3 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 7.2/25.1 MB 30.9 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 8.7/25.1 MB 30.9 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 10.5/25.1 MB 32.7 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 11.8/25.1 MB 34.4 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 13.5/25.1 MB 36.4 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 15.2/25.1 MB 34.4 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 16.2/25.1 MB 31.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 17.6/25.1 MB 32.8 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 19.4/25.1 MB 31.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 21.3/25.1 MB 34.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 22.8/25.1 MB 32.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 24.2/25.1 MB 34.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  25.1/25.1 MB 31.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 25.1/25.1 MB 28.5 MB/s eta 0:00:00\n",
      "Downloading SQLAlchemy-2.0.35-cp310-cp310-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   -------------------------- ------------- 1.4/2.1 MB 29.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 33.5 MB/s eta 0:00:00\n",
      "Downloading waitress-3.0.0-py3-none-any.whl (56 kB)\n",
      "   ---------------------------------------- 0.0/56.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 56.7/56.7 kB 3.1 MB/s eta 0:00:00\n",
      "Downloading aniso8601-9.0.1-py2.py3-none-any.whl (52 kB)\n",
      "   ---------------------------------------- 0.0/52.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 52.8/52.8 kB ? eta 0:00:00\n",
      "Downloading blinker-1.8.2-py3-none-any.whl (9.5 kB)\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Downloading cloudpickle-3.1.0-py3-none-any.whl (22 kB)\n",
      "Downloading databricks_sdk-0.34.0-py3-none-any.whl (565 kB)\n",
      "   ---------------------------------------- 0.0/565.6 kB ? eta -:--:--\n",
      "   --------------------------------------- 565.6/565.6 kB 34.7 MB/s eta 0:00:00\n",
      "Using cached GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
      "Downloading graphql_core-3.2.4-py3-none-any.whl (203 kB)\n",
      "   ---------------------------------------- 0.0/203.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 203.2/203.2 kB 12.1 MB/s eta 0:00:00\n",
      "Downloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
      "Downloading greenlet-3.1.1-cp310-cp310-win_amd64.whl (298 kB)\n",
      "   ---------------------------------------- 0.0/298.4 kB ? eta -:--:--\n",
      "   --------------------------------------- 298.4/298.4 kB 18.0 MB/s eta 0:00:00\n",
      "Downloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "Downloading opentelemetry_api-1.27.0-py3-none-any.whl (63 kB)\n",
      "   ---------------------------------------- 0.0/64.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 64.0/64.0 kB ? eta 0:00:00\n",
      "Downloading importlib_metadata-8.4.0-py3-none-any.whl (26 kB)\n",
      "Downloading opentelemetry_sdk-1.27.0-py3-none-any.whl (110 kB)\n",
      "   ---------------------------------------- 0.0/110.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 110.5/110.5 kB 6.7 MB/s eta 0:00:00\n",
      "Downloading opentelemetry_semantic_conventions-0.48b0-py3-none-any.whl (149 kB)\n",
      "   ---------------------------------------- 0.0/149.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 149.7/149.7 kB ? eta 0:00:00\n",
      "Downloading sqlparse-0.5.1-py3-none-any.whl (44 kB)\n",
      "   ---------------------------------------- 0.0/44.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 44.2/44.2 kB 2.3 MB/s eta 0:00:00\n",
      "Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.6/78.6 kB ? eta 0:00:00\n",
      "Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Using cached gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "Downloading zipp-3.20.2-py3-none-any.whl (9.2 kB)\n",
      "Using cached smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: aniso8601, zipp, waitress, sqlparse, smmap, pyarrow, Mako, itsdangerous, greenlet, graphql-core, deprecated, cloudpickle, click, blinker, sqlalchemy, importlib-metadata, graphql-relay, gitdb, Flask, docker, opentelemetry-api, graphene, gitpython, databricks-sdk, alembic, opentelemetry-semantic-conventions, opentelemetry-sdk, mlflow-skinny, mlflow\n",
      "Successfully installed Flask-3.0.3 Mako-1.3.5 alembic-1.13.3 aniso8601-9.0.1 blinker-1.8.2 click-8.1.7 cloudpickle-3.1.0 databricks-sdk-0.34.0 deprecated-1.2.14 docker-7.1.0 gitdb-4.0.11 gitpython-3.1.43 graphene-3.3 graphql-core-3.2.4 graphql-relay-3.2.0 greenlet-3.1.1 importlib-metadata-8.4.0 itsdangerous-2.2.0 mlflow-2.16.2 mlflow-skinny-2.16.2 opentelemetry-api-1.27.0 opentelemetry-sdk-1.27.0 opentelemetry-semantic-conventions-0.48b0 pyarrow-17.0.0 smmap-5.0.1 sqlalchemy-2.0.35 sqlparse-0.5.1 waitress-3.0.0 zipp-3.20.2\n"
     ]
    }
   ],
   "source": [
    "!pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1810658-6e21-402b-a042-2545771a0b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cf96531-229e-461d-a892-9cb0f248aac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from keras_tuner import HyperModel, RandomSearch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d579ae4d-2a91-403f-8b03-6d8a34aaca11",
   "metadata": {},
   "source": [
    "Check GPU availablilty "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f373305-01bd-44db-9aa9-bae159dc6db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b806f7e2-f3ee-4a22-9815-ba8d7d667947",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f6e8cfb-d448-4593-aa2d-8dd6c3e4f7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the MNIST dataset\n",
    "def load_data():\n",
    "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "    x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize\n",
    "    x_train = np.expand_dims(x_train, axis=-1)\n",
    "    x_test = np.expand_dims(x_test, axis=-1)\n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7626f4d-db6f-46d6-a772-a0818796ac8a",
   "metadata": {},
   "source": [
    "### Define a HyperModel class for Keras Tuner with adjustable hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c293b3d9-bd35-4da8-a9b3-d48c6cd61f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNHyperModel(HyperModel):\n",
    "    def build(self, hp):\n",
    "        model = models.Sequential()\n",
    "        \n",
    "        # Conv1\n",
    "        model.add(layers.Conv2D(\n",
    "            filters=hp.Int('conv1_filters', min_value=16, max_value=64, step=16),\n",
    "            kernel_size=(3, 3),\n",
    "            activation='relu',\n",
    "            input_shape=(28, 28, 1)\n",
    "        ))\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "        \n",
    "        # Conv2_1 and Conv2_2\n",
    "        for i in range(2):\n",
    "            model.add(layers.Conv2D(\n",
    "                filters=hp.Int(f'conv2_filters_{i+1}', min_value=32, max_value=128, step=32),\n",
    "                kernel_size=(3, 3),\n",
    "                activation='relu'\n",
    "            ))\n",
    "        \n",
    "        # MaxPooling\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "        \n",
    "        # Conv3_1 and Conv3_2\n",
    "        model.add(layers.Conv2D(\n",
    "            filters=hp.Int('conv3_filters', min_value=128, max_value=512, step=128),\n",
    "            kernel_size=(3, 3),\n",
    "            activation='relu'\n",
    "        ))\n",
    "        \n",
    "        model.add(layers.Flatten())\n",
    "        \n",
    "        # Fully Connected Layer 1\n",
    "        model.add(layers.Dense(\n",
    "            units=hp.Int('fc1_units', min_value=500, max_value=1000, step=250),\n",
    "            activation='relu'\n",
    "        ))\n",
    "        \n",
    "        # Fully Connected Layer 2\n",
    "        model.add(layers.Dense(\n",
    "            units=hp.Int('fc2_units', min_value=250, max_value=500, step=250),\n",
    "            activation='relu'\n",
    "        ))\n",
    "        \n",
    "        # Output Layer\n",
    "        model.add(layers.Dense(10, activation='softmax'))\n",
    "        \n",
    "        # Compile model\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(\n",
    "                learning_rate=hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG')\n",
    "            ),\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f18faca9-6701-4431-8316-a00dfc6a6d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba25d103-0e27-436d-93f3-47a0c92f6505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48fa2bbb-e9b4-449b-a95e-b436fb8ef322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e4d724-1c58-46ff-8623-b8a071b2834f",
   "metadata": {},
   "source": [
    "### Initialize the Keras Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e1f7169-58bf-46fe-a11e-c2f4a9c2153e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from tuning_results\\mnist_cnn_tuning\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "tuner = RandomSearch(\n",
    "    CNNHyperModel(),\n",
    "    objective='val_accuracy',\n",
    "    max_trials=10,  # Number of different hyperparameter combinations to try\n",
    "    executions_per_trial=2,  # Average results over multiple runs\n",
    "    directory='tuning_results',\n",
    "    project_name='mnist_cnn_tuning'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6dbf461-be97-45aa-9eb8-ce67d3ac1886",
   "metadata": {},
   "source": [
    "### Perform hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29c11d80-5b5d-4ae4-ad26-3b35fb51f1ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
      "Best hyperparameters found:\n",
      "{'conv1_filters': 48, 'conv2_filters_1': 96, 'conv2_filters_2': 96, 'conv3_filters': 256, 'fc1_units': 1000, 'fc2_units': 250, 'learning_rate': 0.0003031375640856382}\n"
     ]
    }
   ],
   "source": [
    "# tuner.search(x_train, y_train, epochs=5, validation_data=(x_test, y_test))\n",
    "with mlflow.start_run():\n",
    "    # Perform hyperparameter search\n",
    "    tuner.search(x_train, y_train, epochs=5, validation_data=(x_test, y_test))\n",
    "    \n",
    "    # Retrieve the best model and hyperparameters\n",
    "    best_model = tuner.get_best_models(num_models=1)[0]\n",
    "    best_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "    \n",
    "    # Log the best hyperparameters\n",
    "    for param, value in best_hyperparameters.values.items():\n",
    "        mlflow.log_param(param, value)\n",
    "    \n",
    "    # Retrieve the best trial's validation accuracy\n",
    "    best_trial = tuner.oracle.get_best_trials(num_trials=1)[0]\n",
    "    best_val_accuracy = best_trial.score\n",
    "    mlflow.log_metric(\"best_val_accuracy\", best_val_accuracy)\n",
    "    \n",
    "    print(\"Best hyperparameters found:\")\n",
    "    print(best_hyperparameters.values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec58c72-4556-4c79-9d28-435ba2ce0a22",
   "metadata": {},
   "source": [
    "### Export model for deployment phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00633b59-d644-4884-acb7-786e776db8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/11 13:14:31 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Shehab\\AppData\\Local\\Temp\\tmpa7sga67a\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Shehab\\AppData\\Local\\Temp\\tmpa7sga67a\\model\\data\\model\\assets\n",
      "2024/10/11 13:14:45 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ./exported_models/best_model_v1_0_1.h5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.keras.models import save_model\n",
    "\n",
    "# Save the best model for deployment\n",
    "model_version = \"v1_0_1\"  # Update this version number as needed\n",
    "model_directory = './exported_models/'\n",
    "model_file_path = os.path.join(model_directory, f'best_model_{model_version}.h5')\n",
    "\n",
    "os.makedirs(model_directory, exist_ok=True)\n",
    "best_model.save(model_file_path)\n",
    "\n",
    "# Log the model with MLflow\n",
    "mlflow.tensorflow.log_model(best_model, artifact_path=\"model\")\n",
    "mlflow.log_param(\"model_version\", model_version)\n",
    "mlflow.end_run()\n",
    "\n",
    "print(f\"Model saved to {model_file_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba492b3-7e39-470a-9981-c2a020598025",
   "metadata": {},
   "source": [
    "### To access the MLflow UI, run !mlflow ui in a terminal, and open http://localhost:5000 in a browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63894ef3-6e8c-449a-b1c2-4049f5ed54cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mlflow ui"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
